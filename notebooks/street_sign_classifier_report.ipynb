{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Sign Classifier Report\n",
    "\n",
    "This project implements a street sign classifier using deep learning. This project is written in Python 3.6. The `keras`, `tensorflow`, and `scikit-learn` packages were used to build the model. Data visualization and preprocessing was done with the `matplotlib` and `scikit-image` packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The following two datasets were considered for this project:\n",
    "\n",
    "* [LISA Traffic Sign Dataset](http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html) - a set of pictures and videos with annotated frames containing US traffic signs.\n",
    "* [BelgiumTS Dataset](https://btsd.ethz.ch/shareddata/) - a set of labelled pictures containing Belgium traffic signs.\n",
    "\n",
    "The BelgiumTS dataset was selected due to its simplicity and smaller size. The LISA dataset is very large, and has far more data than is necessary for a small-scale project like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "The BelgiumTS dataset is pre-split into training and test sets upon download. This would be convenient if we only needed a training and test set. However, we also need a validation set. So instead of using the pre-split data, we merge them back together into a single dataset. We then randomly split this merged dataset into training (60%), validation (20%), and test (20%) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "\n",
    "The BelgiumTS dataset contains 62 classes of street signs, with 7095 images in total. The number of images in each class varies from as few as 6, up to 285. The visualization below contains a single image from each class in the dataset.\n",
    "\n",
    "![btsc-orig-all-classes.png](btsc-orig-all-classes1.png)\n",
    "\n",
    "As you can see from the visualization, the images do not have a standard size. This means that the images must be resized to a standard width and height before they can be fed as input to a  neural network.\n",
    "\n",
    "We resized the images to 32x32 pixels. This was done using `scikit-image`. A few different sizes were tested: 16x16, 32x32, and 64x64. We found that 32x32 gave us the same accuracy as 64x64, while being faster to train with. 16x16 was ruled out because the it resulted in the DNN being ~3% less accurate than with 32x32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "Stuff and things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
